apiVersion: nais.io/v1
kind: Alert
metadata:
  name: harbeidsgiver-alerts-fss
  namespace: default
  labels:
    team: helsearbeidsgiver
spec:
  receivers:
    slack:
      channel: '#helse-arbeidsgiver-alerts'
  alerts:
    - alert: harbeidsgiver-app-nede
      expr: up{app=~"syfoinntektsmelding|spberegning|sporenstreks|sporenstreks-frontend",job="kubernetes-pods"} == 0
      for: 2m
      description: "{{ $labels.app }} er nede <!channel>"
      action: "Se `kubectl describe pod {{ $labels.kubernetes_pod_name }}` for events, og `kubectl logs {{ $labels.kubernetes_pod_name }}` for logger"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: harebeidsgiver-kontinuerlig-restart
      expr: sum(increase(kube_pod_container_status_restarts_total{container=~"syfoinntektsmelding|spberegning|sporenstreks|sporenstreks-frontend"}[30m])) by (container) > 2
      for: 5m
      description: "{{ $labels.container }} har restartet flere ganger siste halvtimen! <!channel>"
      action: "Se `kubectl describe pod {{ $labels.container }}` for events, og `kubectl logs {{ $labels.container }}` for logger"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: harebeidsgiver-mangler-metrikker
      expr: absent(up{app=~"syfoinntektsmelding|spberegning",job="kubernetes-pods"})
      for: 5m
      description: "{{ $labels.app }} rapporterer ingen metrikker"
      action: "Sjekk om {{ $labels.app }} er oppe"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: harebeidsgiver-errorlogging
      expr: (100 * sum by (log_app) (rate(logd_messages_total{log_app=~"spberegning|sporenstreks|sporenstreks-frontend",log_level="Error"}[5m])) / sum by (log_app) (rate(logd_messages_total{log_app=~"spberegning|sporenstreks|sporenstreks-frontend"}[5m]))) > 10
      for: 3m
      description: "{{ $labels.log_app }} rapporterer error i loggene <!channel>"
      action: "Sjekk loggene til {{ $labels.log_app }}, for å se hvorfor det er så mye feil (over 10 feil per 100 logger de siste 5 minuttene)"
      severity: danger
    - alert: harebeidsgiver-errorlogging
      expr: (100 * sum by (log_app) (rate(logd_messages_total{log_app=~"syfoinntektsmelding",log_level="Error"}[15m])) / sum by (log_app) (rate(logd_messages_total{log_app=~"syfoinntektsmelding"}[15m]))) > 20
      for: 3m
      description: "{{ $labels.log_app }} rapporterer error i loggene <!channel>"
      action: "Sjekk loggene til {{ $labels.log_app }}, for å se hvorfor det er så mye feil (over 20 feil per 100 logger de siste 15 minuttene)"
      severity: warning
    - alert: syfoinntektsmelding-mottar-ikke-im
      expr: sum(increase(syfoinntektsmelding_inntektsmeldinger_mottatt_total [20m]) ) < 1 AND hour() > 8 AND hour() < 16 AND day_of_week() < 6 AND day_of_week() > 0
      for: 3m
      description: "{{ $labels.log_app }} Har ikke mottatt noen inntektsmeldinger de siste 20 minuttene"
      action: "Prøv å finn ut hvorfor {{ $labels.log_app }} ikke mottar inntektsmeldinger"
      severity: warning

    - alert: bakgrunnsjobb-feilet-permanent-spinn
      expr: sum(increase(syfoinntektsmelding_bakgrunnsjobb_stoppet_total[5m])) > 1
      for: 1m
      description: "Bakgrunnsjobb feilet permanent i syfoinntektsmelding!! MÅ SJEKKES!"
      action: "https://logs.adeo.no/app/discover#/?_g=(filters:!(),refreshInterval:(pause:!t,value:0),time:(from:now-24h,to:now))&_a=(columns:!(message,envclass,level,application,host),filters:!(),index:'96e648c0-980a-11e9-830a-e17bbd64b4db',interval:auto,query:(language:kuery,query:'application:%20syfoinntektsmelding%20and%20message:%20permanent%20and%20envclass:%20p'),sort:!())"
      severity: danger

    - alert: bakgrunnsjobb-feilet-permanent-sporenstreks
      expr: sum(increase(sporenstreks_bakgrunnsjobb_stoppet_total[5m])) > 1
      for: 1m
      description: "Bakgrunnsjobb feilet permanent i sporenstreks!! MÅ SJEKKES!"
      action: "https://logs.adeo.no/app/discover#/?_g=(filters:!(),refreshInterval:(pause:!t,value:0),time:(from:now-24h,to:now))&_a=(columns:!(message,envclass,level,application,host),filters:!(),index:'96e648c0-980a-11e9-830a-e17bbd64b4db',interval:auto,query:(language:kuery,query:'application:%20sporenstreks%20and%20message:%20permanent%20and%20envclass:%20p'),sort:!())"
      severity: danger
